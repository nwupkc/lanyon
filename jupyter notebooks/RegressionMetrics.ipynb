{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $R^2$ Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $R^2$ statistics is the amount of variance in the dependent variable explained by your model. It is given by the formula:\n",
    "\n",
    "$$R^2 = \\frac{ESS}{TSS} = 1 − \\frac{RSS}{TSS}$$\n",
    "where\n",
    "$$ESS = \\sum\\limits_{i=1}^n (\\hat y_i - \\bar y_i)^2, \\ \n",
    "RSS = \\sum\\limits_{i=1}^n (y_i - \\hat y_i)^2, \\ and \\ \\  \n",
    "TSS = \\sum\\limits_{i=1}^n (y_i - \\bar y_i)^2 \\\\\n",
    "where \\ \\  \\bar y_i = \\sum\\limits_{i=1}^n y_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The explained sum of squares ($ESS$) is a quantity used in describing how well a model represents the data being modeled. In particular, the explained sum of squares measures how much variation there is in the modeled values.\n",
    "\n",
    "The residual sum of squares ($RSS$) is the sum of the squares of residuals. The residuals are deviations of predicted from the actual empirical values of data. $RSS$ is a measure of the discrepancy between the data and an estimation model. A small $RSS$ indicates a tight fit of the model to the data. The residual sum of squares measures the variation in the modeling errors.\n",
    "\n",
    "The total sum of squares ($TSS$) is the sum of the squares of the difference of the dependent variable and its mean. The total sum of squares measures how much variation there is in the observed data.\n",
    "\n",
    "In general, total sum of squares = explained sum of squares + residual sum of squares.\n",
    "$TSS = ESS + RSS$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error and Root-Mean-Square Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean squared error ($MSE$) is another popular metrics in regression settings. The mean squared error is the explained sum of squares divided by the number of observations.\n",
    "$$MSE = \\frac{1}{n} \\cdot RSS = \\frac{1}{n} \\sum\\limits_{i=1}^n (y_i - \\hat y_i)^2$$\n",
    "The root-mean-square error ($RMSE$) is the square root of $MSE$ (i.e. $RMSE = \\sqrt{MSE}$). $RMSE$ has an advantage over $MSE$ because it has the same units as the quantity being estimated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$R^2$ is a standardized measure (from 0 to 1) of model fit. $MSE$ is the estimate of variance of residuals, or non-fit. We want higher $R^2$ and lower $MSE$. The two measures are clearly related as can be seen from here:\n",
    "$$R^2 = 1 − \\frac{RSS}{TSS} = 1 - \\frac{n \\cdot MSE}{TSS}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
